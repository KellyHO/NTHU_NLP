{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import nltk, random\n",
    "from nltk.probability import DictionaryProbDist as D\n",
    "import re\n",
    "from collections import defaultdict, Counter\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lmtzr = WordNetLemmatizer()\n",
    "import nltk, random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leskOverlap(senseDef, target):\n",
    "    wnidCount = [ (wncat, tf, word, len(DF[word])+1) for word in senseDef \\\n",
    "                                                    for wncat, tf in TF[word].items() \\\n",
    "                                                    if wncat in target.values() ]\n",
    "    res = sorted( [ (word, tf*int(1000/df)) for wnid, tf, word, df in wnidCount], key = lambda x: -x[1])[:5]\n",
    "    feature = {}\n",
    "#         print(res)\n",
    "    for i in res:\n",
    "        feature[i[0]] = i[1]\n",
    "#     print(feature)\n",
    "        \n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words(text): return re.findall(r'\\w+', text.lower())\n",
    "    \n",
    "TF = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "DF = defaultdict(lambda: [])\n",
    "\n",
    "def wnTag(pos): return {'noun': 'n', 'verb': 'v', 'adjective': 'a', 'adverb': 'r'}[pos]\n",
    "\n",
    "def trainLesk():\n",
    "    training_x = []\n",
    "    training_y = []\n",
    "    features = []\n",
    "    training = [  line.strip().split('\\t') for line in open('wn.in.evp.cat.txt', 'r') if line.strip() != '' ]\n",
    "#     training = training[:100]\n",
    "#     training, testing = train_test_split(training,test_size=0.2)\n",
    "#     print(training[0])\n",
    "    def isHead(head, word, tag):\n",
    "        try:\n",
    "            return lmtzr.lemmatize(word, tag) == head\n",
    "        except:\n",
    "            return False\n",
    "    tar = []\n",
    "    # zucchini-n-2\tvegetable.n.01\tzucchini courgette||small cucumber-shaped vegetable marrow; typically dark green||\t\n",
    "    # {'zucchini-n-1': 'vine.n.01', 'zucchini-n-2': 'vegetable.n.01'}        \n",
    "    for wnid, wncat, senseDef, target in training:\n",
    "        tar.append(eval(target))\n",
    "#         print(senseDef)\n",
    "        Tf = {}\n",
    "        head, pos = wnid.split('-')[:2]\n",
    "        for word in words(senseDef):\n",
    "            Tf[word] = True\n",
    "#         print(Tf)\n",
    "#         training_x.append(Tf)\n",
    "#         training_y.append(wncat)\n",
    "        \n",
    "            if word != head and not isHead(head, word, pos):\n",
    "#                 f = gender_features(word)\n",
    "#                 print(type(f),f)\n",
    "#                 Tf.append(f)\n",
    "#         training_data.append(Tf)\n",
    "#         training_label.append(wncat)\n",
    "#                 print(word)\n",
    "                TF[word][wncat] += 1\n",
    "                DF[word] += [] if wncat in DF[word] else [wncat]\n",
    "#                 print(TF[word][wncat])\n",
    "#             features.append((Tf,wncat))\n",
    "            \n",
    "\n",
    "    for evpid, wncat, senseDef, target in training:\n",
    "        features.append((leskOverlap(words(senseDef), eval(target)),wncat))\n",
    "        #head, pos = evpid.split('-')[:2]\n",
    "#         print( '%s\\t%s\\t%s' %(evpid, leskOverlap(words(senseDef), eval(target)), senseDef.split('||')[0] ) )\n",
    "#             Tf[word] = True\n",
    "    \n",
    "            \n",
    "#     print(DF[\"abandon\"][\"unconcerned.a.01\"])\n",
    "    return features, tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features,tar = trainLesk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LG_gender(train_set, test_set):\n",
    "    print('== SkLearn MaxEnt ==')\n",
    "    from nltk.classify import SklearnClassifier \n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    sklearn_classifier = SklearnClassifier(LogisticRegression(C=10e5)).train(train_set)\n",
    "#     print(sklearn_classifier.prob_classify(gender_features('mark'))._prob_dict)\n",
    "    print(nltk.classify.accuracy(sklearn_classifier, test_set))\n",
    "    return sklearn_classifier\n",
    "\n",
    "def ME_gender(train_set, test_set):\n",
    "    print('== NLTK MaxEnt ==')\n",
    "    from nltk.classify import MaxentClassifier\n",
    "    nltk_classifier = MaxentClassifier.train(train_set, nltk.classify.MaxentClassifier.ALGORITHMS[0])\n",
    "#     print(nltk_classifier.prob_classify(gender_features('mark'))._prob_dict)\n",
    "    print(nltk.classify.accuracy(nltk_classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23194\n"
     ]
    }
   ],
   "source": [
    "print(len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = features[:20000]\n",
    "targets = tar[:20000]\n",
    "split_point = len(testset)*9//10\n",
    "train_set, test_set = testset[:split_point], testset[split_point:]\n",
    "testing_target = targets[split_point:]\n",
    "\n",
    "# classifier = LG_gender(train_set, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(split_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.403\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.externals import joblib\n",
    "clf = joblib.load('filename.pkl') \n",
    "print(nltk.classify.accuracy(clf, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotional.a.02\n",
      "tender.a.01\n"
     ]
    }
   ],
   "source": [
    "# print(type(testing_target))\n",
    "for i in testing_target[0]:\n",
    "    print(testing_target[0].get(i))\n",
    "#     print(list(i.values())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'marked': 8, 'given': 24, 'by': 1, 'sentiment': 333, 'sentimentality': 500}, 'tender.a.01')\n",
      "dict_values(['emotional.a.02', 'tender.a.01'])\n"
     ]
    }
   ],
   "source": [
    "a = test_set[0]\n",
    "print(a)\n",
    "prob_d = clf.prob_classify(a[0])._prob_dict\n",
    "print(testing_target[0].values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nonstandard.a.01'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_d.get('emotional.a.02')\n",
    "max(testing_target[0].values(),key=lambda x: prob_d.get(x, 0))\n",
    "# print(prob_d)\n",
    "# print(test_set[2])\n",
    "clf.classify(test_set[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'by': 1, 'given': 24, 'marked': 8, 'sentiment': 333, 'sentimentality': 500},\n",
       " 'tender.a.01')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fun/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/base.py:340: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1310\n"
     ]
    }
   ],
   "source": [
    "hits = 0\n",
    "for i in range(len(test_set)):\n",
    "    prob_d = clf.prob_classify(test_set[i][0])._prob_dict\n",
    "#     corr = max(prob_d)\n",
    "#     print(corr)\n",
    "    corr = test_set[i][1]\n",
    "#     max_v = 0\n",
    "    max_s = max(testing_target[i].values(),key=lambda x: prob_d.get(x, 0))\n",
    "#     for j in testing_target[i]:\n",
    "     \n",
    "#         max_s = ''\n",
    "#         try:\n",
    "#             n = prob_d.get(testing_target[0].get(j))\n",
    "# #             print(n)\n",
    "#             if n > max_v:\n",
    "#                 max_s = testing_target[0].get(j)\n",
    "#         except:\n",
    "#             pass\n",
    "    \n",
    "    if corr == max_s:\n",
    "        hits +=1\n",
    "print(hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.externals import joblib\n",
    "# joblib.dump(classifier, 'filename.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.655\n"
     ]
    }
   ],
   "source": [
    "print(1310/len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLs():\n",
    "\n",
    "    training = [  line.strip().split('\\t') for line in open('evp.in.wn.cat.txt', 'r',encoding='UTF8') if line.strip() != '' ]\n",
    "    \n",
    "    def isHead(head, word, tag):\n",
    "        try:\n",
    "            return lmtzr.lemmatize(word, tag) == head\n",
    "        except:\n",
    "            return False\n",
    "            \n",
    "    # zucchini-n-2\tvegetable.n.01\tzucchini courgette||small cucumber-shaped vegetable marrow; typically dark green||\t\n",
    "    # {'zucchini-n-1': 'vine.n.01', 'zucchini-n-2': 'vegetable.n.01'}        \n",
    "    for wnid, wncat, senseDef, target in training:\n",
    "#         print(senseDef)\n",
    "        Tf = {}\n",
    "        head, pos = wnid.split('-')[:2]\n",
    "        for word in words(senseDef):\n",
    "            Tf[word] = True\n",
    "#         print(Tf)\n",
    "#         training_x.append(Tf)\n",
    "#         training_y.append(wncat)\n",
    "        \n",
    "            if word != head and not isHead(head, word, pos):\n",
    "#                 f = gender_features(word)\n",
    "#                 print(type(f),f)\n",
    "#                 Tf.append(f)\n",
    "#         training_data.append(Tf)\n",
    "#         training_label.append(wncat)\n",
    "#                 print(word)\n",
    "                TF[word][wncat] += 1\n",
    "                DF[word] += [] if wncat in DF[word] else [wncat]\n",
    "#                 print(TF[word][wncat])\n",
    "#             features.append((Tf,wncat))\n",
    "    t = []        \n",
    "\n",
    "    for evpid, wncat, senseDef, target in training:\n",
    "        features.append((leskOverlap(words(senseDef), eval(target)),wncat))\n",
    "        t.append(target)\n",
    "        \n",
    "#     print(t)\n",
    "    hits = 0\n",
    "    for i in testing:\n",
    "        corr = sorted(classifier.prob_classify(i[0])._prob_dict)[:1]\n",
    "        for j in t:\n",
    "            max_v = 0\n",
    "            max_s = ''\n",
    "            try:\n",
    "                n = classifier.prob_classify(i[0])._prob_dict.get(j)\n",
    "                if n > max_v:\n",
    "                    max_s = j\n",
    "            except:\n",
    "                pass\n",
    "        if corr == max_s:\n",
    "            hits +=1\n",
    "            \n",
    "            \n",
    "        #head, pos = evpid.split('-')[:2]\n",
    "#         print( '%s\\t%s\\t%s' %(evpid, leskOverlap(words(senseDef), eval(target)), senseDef.split('||')[0] ) )\n",
    "#             Tf[word] = True\n",
    "    \n",
    "    print(hits)\n",
    "#     print(DF[\"abandon\"][\"unconcerned.a.01\"])\n",
    "    return hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "getLs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(/len(training))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
