{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "from math import log\n",
    "\n",
    "'''Word Probability'''\n",
    "def words(text): return re.findall(r'\\w+', text.lower())\n",
    "count_word = Counter(words(open('big.txt').read()))\n",
    "Nw = sum(count_word.values())\n",
    "Pdist = {word: float(count)/Nw for word, count in count_word.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correction(word):\n",
    "    MAXBEAM = 500\n",
    "    total_state = []\n",
    "    states = [(\"\", word, 0, Pw(word),1)]\n",
    "    for i in range(len(word)):\n",
    "#         print(i, states[:3])\n",
    "        new_s = []\n",
    "        for s in states:\n",
    "            new_s += next_states(s)\n",
    "        states = new_s\n",
    "        d = {}\n",
    "        for i in states:\n",
    "            if i[0]+i[1] in d:\n",
    "                if d[i[0]+i[1]][2] > i[2]:\n",
    "                    d[i[0]+i[1]] = i\n",
    "            else:\n",
    "                d[i[0]+i[1]] = i\n",
    "        states = d.values()\n",
    "        states = sorted(states, key=lambda x: x[2]) \n",
    "        states = sorted(states, key=lambda x: P(x[4],x[3]),reverse=True)[:MAXBEAM] \n",
    "#         pprint(states[:3])\n",
    "#     return max(states[:3])\n",
    "    return states[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_states(state):\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    L, R, edit, pw, pedit = state\n",
    "    R0, R1 = R[0], R[1:]\n",
    "    if edit == 2: return [(L + R0 , R1 , edit ,pw, pedit*0.8 )]\n",
    "    noedit = [(L + R0 , R1 , edit ,pw, pedit*0.8 )]\n",
    "    delete  =[(L , R1, edit+1,Pw(L+R1), pedit*Pedit(L[-1]+R0,L[-1]))] if len(L)>0 else []\n",
    "    replace =[(L +c, R1 , edit+1, Pw(L+c+R1), pedit*Pedit(R0,c) )for c in letters]\n",
    "    insert = [(L + R0 + c , R1 ,edit+1,Pw(L + R0 + c + R1), pedit*Pedit(R0,R0+c))for c in letters]\n",
    "    transpose = [( L[:-1] + R0 ,L[-1]+ R1 , edit+1,Pw(L[:-1] + R0 +L[-1]+ R1), pedit+Pedit(L[-1]+R0,R0+L[-1]))] if len(L)>0 else []\n",
    "#     transpose = [( L + R1[0] ,R0+ R1[1:] , edit+1,Pw(L + R1[0] +R0+ R1[1:]), pedit+Pedit(L + R1,R0+R1[1:]))]\n",
    "\n",
    "#     delete  =[(L , R1, edit+1,Pw(L+R1), pedit*Pedit(R0,\"\"))]  #if len(L)>0 else []\n",
    "\n",
    "    return noedit + delete + replace + insert + transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "def known(words): \n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in WORDS)\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word):\n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = {}\n",
    "count_c = {}\n",
    "for line in open('count_1.txt', 'r'):\n",
    "#     print(line.split()[0],line.split()[1])\n",
    "#     print(line.split('\\t')[0].split('|')[0],line.split('\\t')[0].split('|')[1])\n",
    "    count[(line.split('\\t')[0].split('|')[0],line.split('\\t')[0].split('|')[1])] = int(line.split('\\t')[1].strip('\\n'))\n",
    "    if line.split('\\t')[0].split('|')[1] in count_c:\n",
    "        count_c[line.split('\\t')[0].split('|')[1]] += 1\n",
    "    else:\n",
    "        count_c[line.split('\\t')[0].split('|')[1]] = 1\n",
    "\n",
    "\n",
    "Nall = len(count)\n",
    "N0 =  26*26*26*26+2*26*26*26+26*26 - Nall\n",
    "All_N_Count =  Counter(count.values())\n",
    "# print(All_N_Count)\n",
    "Nr = [ N0 if r == 0 else All_N_Count[r] for r in range(12) ]\n",
    "# print(Nr)\n",
    "\n",
    "def Pw(word, N=sum(count_word.values())): \n",
    "#     if word in count_word:\n",
    "    return count_word[word] / N\n",
    "#     else:\n",
    "#         return 0\n",
    "#         print(10/10**len(word)/Nw)\n",
    "#         return (1/1000**len(word))/N\n",
    "\n",
    "def smooth(count, r=10):\n",
    "#     print(type(count))\n",
    "    r = int(r)\n",
    "    if int(count) <= r:\n",
    "#         if (count+1)*0.7*Nr[count+1]/Nr[count] > 1:\n",
    "#             print(count,(count+1)*Nr[count+1],Nr[count])\n",
    "        return (count+1)*Nr[count+1]/Nr[count]\n",
    "    else:\n",
    "#         print('smooth',All_N_Count[count])\n",
    "#         return 0\n",
    "        return All_N_Count[count]\n",
    "\n",
    "def Pedit(w, c):\n",
    "    if c in count_c:\n",
    "        if count_c[c] > 0:\n",
    "            if (w,c) not in count:\n",
    "#                 return log(smooth(0))\n",
    "#                 print('up',w,c,smooth(0),count_c[c])\n",
    "                return smooth(0)/count_c[c]\n",
    "\n",
    "            else:\n",
    "                try:\n",
    "#                     if smooth(count[(w,c)])/(count_c[c]) > 1:\n",
    "#                         print('under',w,c, smooth(count[(w,c)]),count_c[c])\n",
    "                    return smooth(count[(w,c)])/count_c[c]\n",
    "                except:\n",
    "                    print(count_c[c])\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# '''Combining channel probability with word probability to score states'''\n",
    "def P(pedit, pw):\n",
    "#     return pw\n",
    "    return pw*pedit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[491217, 317, 184, 99, 90, 74, 50, 50, 45, 37, 30, 27]\n",
      "0.580441640378549\n",
      "184\n"
     ]
    }
   ],
   "source": [
    "print(Nr)\n",
    "print(Nr[2]*1/Nr[1])\n",
    "print(Nr[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('get', 's', 2, 1.9720595024135318e-05, 7.026122448979592),\n",
       " ('go', '', 2, 0.0008112335680382938, 0.08414039262343845),\n",
       " ('lot', 's', 2, 7.171125463321934e-06, 7.01651033999299),\n",
       " ('most', '', 1, 0.0008139227400870395, 0.05765765765765768),\n",
       " ('got', '', 1, 0.0002509893912162677, 0.16234146341463418),\n",
       " ('gross', '', 2, 2.509893912162677e-05, 1.393777777777778),\n",
       " ('moist', '', 2, 5.467983165782975e-05, 0.46846846846846857),\n",
       " ('get', '', 2, 0.00041951083960433316, 0.04877057508636458),\n",
       " ('pot', 's', 2, 2.6891720487457255e-06, 7.021851920578957),\n",
       " ('ghost', '', 1, 6.2747347804066925e-06, 2.5600000000000005)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correction('gost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['they', 'kill', 'birds', 'with', 'their', 'nerrow']\n",
      "not found\n",
      "{'they kill birds': 239.0, 'kill birds with': 116.0, 'birds with their': 3270.0, 'with their nerrow': 0}\n",
      "['with their nerrow', 'kill birds with', 'they kill birds', 'birds with their']\n"
     ]
    }
   ],
   "source": [
    "import LinggleAPI\n",
    "import requests\n",
    "import math\n",
    "\n",
    "SE = LinggleAPI.Linggle()\n",
    "    # Search_Result = SE.search(\"approach that *\")\n",
    "    # print Search_Result\n",
    "    # at * time\n",
    "# test = 'when the brake is finished'.split()\n",
    "raw_test = 'they kill birds with their nerrow'\n",
    "\n",
    "test = raw_test.lower().split()\n",
    "print(test)\n",
    "    # test = '? is finished'\n",
    "    # test = 'brake is finished'\n",
    "    \n",
    "trigram = {}\n",
    "\n",
    "\n",
    "for i in range(len(test) - 2):\n",
    "#     print(i)\n",
    "    now_tri = ' '.join(test[i:i + 3])\n",
    "    res = SE[now_tri]\n",
    "    if res:\n",
    "        c = '\\n'.join('\\t'.join([str(y) for y in x]) for x in res)\n",
    "        trigram[now_tri] = float(c.split('\\t')[1])\n",
    "#         print('\\n'.join('\\t'.join([str(y) for y in x]) for x in res))\n",
    "\n",
    "    else:\n",
    "        trigram[now_tri] = 0\n",
    "        \n",
    "        print('not found')\n",
    "        \n",
    "print(trigram)\n",
    "can_tri = sorted(trigram,key = trigram.get)\n",
    "# for same in sorted(trigram,key = trigram.get):\n",
    "    \n",
    "print(can_tri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "candidates = []\n",
    "sen_and_err = {}\n",
    "for i, t in enumerate(str(can_tri).split(' ')):\n",
    "    if len(t) < 3:\n",
    "        pass\n",
    "    else:\n",
    "#         print(t)\n",
    "        for c in correction(t):\n",
    "            s = []\n",
    "            for ot in test:\n",
    "                print(ot)\n",
    "                if str(t) == str(ot):\n",
    "                    s.append(c[0]+c[1])\n",
    "                else:\n",
    "                    s.append(ot)\n",
    "            print(s)\n",
    "#             candidates[str(t)] = \n",
    "#             candidates.append('\\t'.join([str(y) for y in s]))\n",
    "            candidates.append(s)\n",
    "            sen_and_err['\\t'.join([str(y) for y in s])] = (str(t),c[0]+c[1])\n",
    "                \n",
    "#                     a[n] = 10\n",
    "#             print(test[i])\n",
    "#             print(i[0])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sen_and_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "score = {}\n",
    "for test in candidates:\n",
    "    print(test)\n",
    "    can_trigram = {}\n",
    "    tri_m_sum = 1\n",
    "    for i in range(len(test) - 2):\n",
    "        now_tri = ' '.join(test[i:i + 3])\n",
    "        res = SE.search(' '.join(test[i:i + 3]))\n",
    "        if res:\n",
    "            c = '\\n'.join('\\t'.join([str(y) for y in x]) for x in res)\n",
    "            can_trigram[now_tri] = float(c.split('\\t')[1])\n",
    "            print('\\n'.join('\\t'.join([str(y) for y in x]) for x in res))\n",
    "        else:\n",
    "            can_trigram[now_tri] = 0\n",
    "            print('not found')\n",
    "            \n",
    "    for k in can_trigram.values():\n",
    "        tri_m_sum *= k\n",
    "        \n",
    "    score['\\t'.join([str(y) for y in test])] = tri_m_sum\n",
    "#     print(sum(c for c in can_trigram.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pprint(can_trigram)\n",
    "pprint(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max(score,key = score.get))\n",
    "# print(score)\n",
    "7433913360\n",
    "255563436120\n",
    "# error_sen = '\\t'.join([str(y) for y in test])\n",
    "# correction_sen = max(score, key=score.get)\n",
    "# print(correction_sen)\n",
    "# print(max(can_trigram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_text = sen_and_err.get(correction_sen)[0]\n",
    "correction_text = sen_and_err.get(correction_sen)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Error:\",error_text)\n",
    "print(\"Candidates:\")\n",
    "for i in correction(error_text):\n",
    "    print(i[0])\n",
    "print(\"Correction:\",correction_text)\n",
    "print(raw_test ,'--->',correction_sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data = open('lab4.test.1.txt')\n",
    "testing_dict = {}\n",
    "for i in testing_data.readlines()[:20]:\n",
    "    testing_dict[i.split('\\t')[0].lower().strip()] = i.split('\\t')[1].lower().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in testing_dict:\n",
    "    print(i,'|',testing_dict.get(i))\n",
    "print(testing_dict.get('i felt very strang'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_word = open('lab4.confusables.txt')\n",
    "fusion_dict = {}\n",
    "for i in fusion_word.readlines():\n",
    "    fusion_dict[i.split('\\t')[0].lower().strip()] = i.split('\\t')[1].lower().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits = 0\n",
    "import NetSpeakAPI\n",
    "SE = NetSpeakAPI.NetSpeak()\n",
    "for i in testing_dict:\n",
    "\n",
    "# def CORRECTION(raw_test):\n",
    "    global hits\n",
    "    raw_test = i\n",
    "    \n",
    "#     raw_test = 'I felt very strang'\n",
    "    test = raw_test.lower().split()\n",
    "    \n",
    "    trigram = {}\n",
    "\n",
    "\n",
    "    for i in range(len(test) - 2):\n",
    "        now_tri = ' '.join(test[i:i + 3])\n",
    "        res = SE.search(' '.join(test[i:i + 3]))\n",
    "        if res:\n",
    "            c = '\\n'.join(' '.join([str(y) for y in x]) for x in res)\n",
    "#             print(c)\n",
    "            trigram[now_tri] = float(c.split(' ')[-1])\n",
    "#         print('\\n'.join('\\t'.join([str(y) for y in x]) for x in res))\n",
    "        else:\n",
    "            trigram[now_tri] = 0\n",
    "#             print('not found')\n",
    "    \n",
    "#     print(trigram)\n",
    "    can_tri = min(trigram,key=trigram.get)\n",
    "    \n",
    "    candidates = []\n",
    "    sen_and_err = {}\n",
    "    for i, t in enumerate(str(can_tri).split(' ')):\n",
    "        if len(t) < 3:\n",
    "            pass\n",
    "        else:\n",
    "            for c in correction(t):\n",
    "                s = []\n",
    "\n",
    "                for ot in test:\n",
    "                    if str(t) == str(ot):\n",
    "                        s.append(c[0]+c[1])\n",
    "                    else:\n",
    "                        s.append(ot)\n",
    "#                 print(s)\n",
    "#             candidates[str(t)] = \n",
    "#             candidates.append('\\t'.join([str(y) for y in s]))\n",
    "                candidates.append(s)\n",
    "                sen_and_err[' '.join([str(y) for y in s])] = (str(t),c[0]+c[1])\n",
    "        \n",
    "    score = {}\n",
    "#     print(candidates)\n",
    "    for test in candidates:\n",
    "#         print(test)\n",
    "        can_trigram = {}\n",
    "        m_sum = 1\n",
    "        for i in range(len(test) - 2):\n",
    "            now_tri = ' '.join(test[i:i + 3])\n",
    "            res = SE.search(' '.join(test[i:i + 3]))\n",
    "            if res:\n",
    "                c = '\\n'.join(' '.join([str(y) for y in x]) for x in res)\n",
    "                can_trigram[now_tri] = float(c.split(' ')[-1])\n",
    "#                 print('\\n'.join(' '.join([str(y) for y in x]) for x in res))\n",
    "            else:\n",
    "                can_trigram[now_tri] = 0\n",
    "#                 print('not found')\n",
    "    \n",
    "        for k in can_trigram.values():\n",
    "            m_sum *= k\n",
    "        score[' '.join([str(y) for y in test])] = m_sum\n",
    "    \n",
    "    error_sen = ' '.join([str(y) for y in test])\n",
    "    correction_sen = max(score, key=score.get)\n",
    "    error_text = sen_and_err.get(correction_sen)[0]\n",
    "    correction_text = sen_and_err.get(correction_sen)[1]\n",
    "    \n",
    "#     for i, t in enumerate(str(can_tri).split(' ')):\n",
    "#         if t in fusion_dict:\n",
    "#             correction_text = fusion_dict[t]\n",
    "#             error_text = t\n",
    "#             for n, token in enumerate(raw_test.lower()):\n",
    "#                 if token == t:\n",
    "#                     raw_test.lower()[n] = correction_text\n",
    "#             break\n",
    "    \n",
    "    print(\"Error:\",error_text)\n",
    "    print(\"Candidates:\")\n",
    "    for i in correction(error_text):\n",
    "        print(i[0])\n",
    "    print(\"Correction:\",correction_text)\n",
    "    print(raw_test ,'--->',correction_sen)\n",
    "    if testing_dict.get(raw_test.lower()) == correction_sen:\n",
    "        hits += 1\n",
    "    print(hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in testing_dict:\n",
    "    CORRECTION(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in testing_dict:\n",
    "    raw_test = i\n",
    "    test = raw_test.lower().split()\n",
    "    print(test)\n",
    "    # test = '? is finished'\n",
    "    # test = 'brake is finished'\n",
    "    \n",
    "    trigram = {}\n",
    "\n",
    "\n",
    "    for i in range(len(test) - 2):\n",
    "        now_tri = ' '.join(test[i:i + 3])\n",
    "        res = SE[now_tri]\n",
    "        if res:\n",
    "            c = '\\n'.join('\\t'.join([str(y) for y in x]) for x in res)\n",
    "            trigram[now_tri] = float(c.split('\\t')[1])\n",
    "#         print('\\n'.join('\\t'.join([str(y) for y in x]) for x in res))\n",
    "\n",
    "        else:\n",
    "            trigram[now_tri] = 0\n",
    "            print('not found')\n",
    "        \n",
    "    print(trigram)\n",
    "    can_tri = min(trigram,key = trigram.get) \n",
    "    print(can_tri)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
